{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this project, we would use breast cancer wisconsin dataset from Scikit-Learn to demostrate/review the basic workflows on Data Analysis. Examples steps include understanding and cleaning the data, training and evaluating the data, tuning performance, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we would like to import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "breat_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The breat cancer dataset includes the following elements: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(f'The breat cancer dataset includes the following elements: {breat_cancer.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's further explore by selecting some data samples from each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breat_cancer['data'][0] #all numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(breat_cancer['target']) #We have two classes, what those classes represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breat_cancer['target_names'] #We still do not know if 0 means malignant or benign..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To find out what do 0, 1 represent in the target, we would try the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breat_cancer['DESCR']) \n",
    "#From the description, we come to know that Class Distribution: 212 - Malignant, 357 - Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 212, 1: 357}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we try to get the value counts:\n",
    "cl, cl_counts = np.unique(breat_cancer['target'], return_counts = True)\n",
    "dict(zip(cl, cl_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we come into a conclusion that 0 means malignant, 1 means benign. This is countrary to our(or my) common belief that 1 means malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lastly, let's look at feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breat_cancer['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature names are useful for interpreting the results. However, since we are focusing on making best predictions in this project, we would not use feature_names. So the part of understanding the data is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we would check if the data is complete by checking for NA values, first, we would assign the data to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breat_cancer['data']\n",
    "y = breat_cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X contains NA values: False\n",
      "y contains NA values: False\n"
     ]
    }
   ],
   "source": [
    "#Check for NA values\n",
    "print(f'X contains NA values: {np.isnan(X).any()}')\n",
    "print(f'y contains NA values: {np.isnan(y).any()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great, we do not have any NA values, we would move on to the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we would try to select a model to predict whether the breast cancer is malignant or benign. We would start from Support Vector Machines (SVM), since it generally has good performance and there are some hyper-parameters we could tune for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start by spliting the data into Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.1, random_state = 1, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We stratify by y so that we have the same class proportions in train, test as well as the full sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we would standardize our data to make sure SVM works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining above and SVM model, we can actually make a pipeline for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe_svm = make_pipeline(StandardScaler(), SVC(kernel = 'linear', probability = True, random_state = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we would actually further divide the training set into a sub_training and cross_validation set, because we would like to hold out the test set for final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_sub, X_cv, y_train_sub, y_cv = train_test_split(X_train, y_train, test_size = 0.2, random_state = 1, stratify = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we are ready to move on and fit the pipeline once and evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm.fit(X_train_sub, y_train_sub)\n",
    "pred_cv = pipe_svm.predict(X_cv)\n",
    "predprob_cv = pipe_svm.predict_proba(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_pred     0   1\n",
       "y_actual        \n",
       "0         36   2\n",
       "1          2  63"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.Series(pred_cv, name = 'y_pred').reset_index(drop = True)\n",
    "y_actual = pd.Series(y_cv, name = 'y_actual').reset_index(drop = True)\n",
    "pd.crosstab(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems the result is already pretty good by looking at the number of TP and TN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For evaluation metrics, we would use f1 score and recall - f1 score is useful when we have unbalanced classes and recall is used to evaluate that out of all people who have breast cancer, how many we accurately captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the f1 score is 0.9473684210526315\n",
      "the recall score is 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score\n",
    "print(f'the f1 score is {f1_score(y_cv, pred_cv, pos_label = 0)}')\n",
    "print(f'the recall score is {recall_score(y_cv, pred_cv, pos_label = 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another evaluation method is the ROC curve, ROC curve plot the FPR vs TPR while changing cutoff measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(y_cv, predprob_cv[:, 0], pos_label = 0)\n",
    "plt.plot(fpr, tpr, c = 'red', lw = 2, label = f'Area under curve: {round(auc(fpr, tpr), 3)}')\n",
    "plt.plot([0, 1], [0, 1], ls = '--', label = 'Random Guessing')\n",
    "plt.plot([0, 0, 1], [0, 1, 1], ls = '-.', c = 'green', label = 'Perfect Situation')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now if we would like to continue to improve the metrics such as the f1 score, it would be useful to plot a learning_curve to see if the model has bias or variance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(score_func = f1_score, pos_label = 0)\n",
    "train_sizes, train_scores, cv_scores = learning_curve(pipe_svm, X_train, y_train, train_sizes = np.linspace(0.2, 1, 5), cv = 10, scoring = f1_scorer, n_jobs = -1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis = 1)\n",
    "train_scores_std = np.std(train_scores, axis = 1)\n",
    "cv_scores_mean = np.mean(cv_scores, axis = 1)\n",
    "cv_scores_std = np.std(cv_scores, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20fecddf9c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAGDCAYAAACIpnxcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZwcVb3///enZ8k2WSSBkIUsAiJJSEIYAjEIE4IQvAoICoQAwg8Y8Sd4eShovPgV5Brhov5AEZQoiHojARUB/aGI0QHDlkWSQBIhYQmEBAIBsme2/nz/6OqZ6m2mJ+me6sy8no9HP7r61Kmq02d6pt9z6nSXubsAAADQ+WJRNwAAAKC7IogBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBqBLM7M/m9nno24HAGRDEANQFGb2mpmdFHU73P1Ud/9lMfZtZv3M7FYze93MtpvZ2uDxoGIcD0DXQxADsM8ys/IIj10paYGksZJmSOon6WOSNkuavAf7i+y5AIgOQQxApzOzT5nZMjP7wMyeMrPxoXWzzexlM9tmZqvM7DOhdReZ2ZNmdouZvSfp+qBsoZl938zeN7NXzezU0DZ1ZnZpaPu26o42syeCY//NzG43s//N8TQulDRC0mfcfZW7x919k7v/t7s/EuzPzeyQ0P7vMbPvBMs1ZrbezL5uZm9J+oWZrTazT4Xql5vZu2Y2KXh8bNBfH5jZcjOr2ZufA4DoEcQAdKogVNwt6QuSBkq6U9LDZtYjqPKypI9L6i/p25L+18yGhHZxjKRXJB0gaU6o7EVJgyTdLOkuM7McTWir7m8kLQradb2kC9p4KidJ+ou7b2//Wed0oKT9JI2UVCvpXkkzQ+tPkfSuu//LzIZJ+v8lfSfY5mpJvzez/ffi+AAiRhAD0Nkuk3Snuz/r7s3B/K16ScdKkrv/1t03BCNM90lao9RTfRvc/TZ3b3L3XUHZOnf/mbs3S/qlpCGSBuc4fta6ZjZC0tGSvuXuDe6+UNLDbTyPgZI27lEPtIpLus7d64Pn8htJp5lZ72D9eUGZJJ0v6RF3fyTom8ckLZH0yb1sA4AIEcQAdLaRkr4anF77wMw+kHSQpKGSZGYXhk5bfiBpnBKjV0lvZNnnW8kFd98ZLFblOH6uukMlvRcqy3WspM1KhLi98Y677w61Z62k1ZI+HYSx09QaxEZK+lxavx1XgDYAiBCTQwF0tjckzXH3OekrzGykpJ9Jmi7paXdvNrNlksKnGb1I7dooaT8z6x0KYwe1Uf9vkr5jZn3cfUeOOjsl9Q49PlDS+tDjbM8leXoyJmlVEM6kRL/92t0va+d5ANiHMCIGoJgqzKxn6FauRNC63MyOsYQ+ZvYfZtZXUh8lwsk7kmRmFysxIlZ07r5OiVN915tZpZlNkfTpNjb5tRLh6Pdm9lEzi5nZQDP7LzNLni5cJuk8MyszsxmSTsijKfMlnSzpi2odDZOk/1VipOyUYH89gwn/wzv4VAGUEIIYgGJ6RNKu0O16d1+ixDyxH0t6X9JaSRdJkruvkvQDSU9LelvSEZKe7MT2zpI0RYnTjt+RdJ8S89cyuHu9EhP2/y3pMUlblZjoP0jSs0G1/1QizH0Q7PvB9hrg7huVeP4fC46fLH9D0umS/kuJoPqGpGvE33Fgn2buxRrlB4B9m5ndJ+nf7n5d1G0B0DXxnxQABMzsaDM7ODjNOEOJEah2R7EAYE8xWR8AWh0o6QElvppivaQvuvtz0TYJQFfGqUkAAICIcGoSAAAgIgQxAACAiOyTc8QGDRrko0aNiroZGXbs2KE+ffpE3YySQp9kok8y0Sep6I9M9Ekm+iRTqfbJ0qVL33X3rNeF3SeD2KhRo7RkyZKom5Ghrq5ONTU1UTejpNAnmeiTTPRJKvojE32SiT7JVKp9Ymbrcq3j1CQAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABCRogYxM7vbzDaZ2Qs51puZ/cjM1prZCjObVMz25GXePGnUKCkWS9zPmxd1iwAAQBdV7BGxeyTNaGP9qZIODW61kn5S5Pa0bd48qbZWWrdOck/c19YSxgAAQFGUF3Pn7v6EmY1qo8rpkn7l7i7pGTMbYGZD3H1jMduV07XXSjt3ppbt3CldeaW0Y4dUXp64VVS0LoduA154QSory7ou5ZZje5WVSWaRPHUoEbivvVZ6/XVpxAhpzhxp1qyoWwUA6MIskYGKeIBEEPuTu4/Lsu5Pkm5y94XB4wWSvu7uS7LUrVVi1EyDBw8+av78+QVv6wknnigrcn+0x2MxeVlZu7d4eXnbdfLZT3v7KMD2O+rr1atv3/b3EYtFGkIP+NvfdNj3v6+y+vqWsuYePfTi1Vdr00knFfRY27dvV1VVVUH3ua+jT1LRH5nok0z0SaZS7ZNp06YtdffqbOuKOiKWh2zvvFmTkLvPlTRXkqqrq72mpqbwrRkxInE6Mt2wYVJdndTUJDU2Jm7NzYn7ZFlTk55buVJHjh6dWi+53NwsNTSk1M92s+ZmWfJxc3PruuTxmptby3PdNzSklrVVP3yMqJWVtY4otnefXE6OLmZbn8/j5O3nP5dCIUySyurrNeaOOzRmyJDWkczw8Sors49yhuulj35WVuqJJUt0/FFHJdalB9DkcrayXOu7gLq6OhXldzpfJTYaGnl/lCD6JBN9kqlDfVIiv/dRB7H1kg4KPR4uaUNEbUn8EGprU09P9u4t/c//SIcc0u7mW3r0kAr5S+GeuCWXC1EWjyeWw/fJ5WQga2jICJlZg2W4LD3UBY9Xbtyosfvtlz1YtnXf1JRoV3jfOY7R8ri+vu3wGV4Oh9rGxtw/g/ffl664Yu9+jmmODz8wyx4ScwXPXMsVFdlDZjIwJtcl66UHx3CwzBUyw/fJ5bbCaLZ7s+zB0j3xuguXhZeLGUyTc0OTv/fJuaESp6a7gxJ5M0YnK6Hf+6iD2MOSrjCz+ZKOkbQlsvlhUmvnl8ovZfqbVinLEQDfWbhQmjp1z8NjOCiG75N1swXK9HrpZdnU1Egbs7z0Bg+W7r03M0BmW841apkWCl9++20dPGBA9m3aGvXMVm/nzuyjq+G2pW8f5ehnjoB5rCT16JFf6GxvuY1b8nS4ysvl5YnlshtvlGWZG+pfvlINO7bKkgP3MZOl/z5aLO1h62OT0n5/U3+fTZZyTsBC6/dbt056883M3//2/h60V78jj7P9/Ynwcb+1a6Vdu5TTnjy3BQukW25pHQ1ft0665BLp+eeladMy/yaFb8mybOsKuU14ukxa2QGvviq99FLufRTiOO1tE1rnoTJP2SaeONflLpe3TgFK2yZ1X63bJLb3YFWinoW3DbXt4HffU+Ov75HHW4+TaEvoPcNdFQ/+Mevvva69ttPf84s6R8zM7pVUI2mQpLclXSepQpLc/aeW+Kv2YyU+WblT0sXZ5oelq66u9iVL2q3W6RgmzlSSfZLtD+JvfiNdfnnmaOgdd0jnnpt9m7bus4XC4L5u+XLVHHFEu/VS7nPt1z3xhtKRe6l1xLGxsfU+PfSFy9ODZbYRzPQRyuSIZltBNVi38d13NaSqSp4sb2yUNzeljMB6tmAZaoOltceaEsexXOEbQEnwZDBO/PeSKDQLyhWE6NA/LkF9Tx8RN1PcpVhZor5b6rqWfZip7N33ss6Nklnuf9j3gplFM0fM3We2s94lfamYbQAyZDuddcEFiflanTEaWl6eGGkrhI4GxFz3yeW21sfjcnd5vLnlPh5vlnt6eVwulzc3K+5xxeNNisdd8XiTmrxJ8eZmxeWKxxPrPd6sNRt3aNsBldmfolzyxB9Qc7X+Mfbk325rGU1K/KlNjFzFgnuLu6w5rlhzvDW0NTdLzXFZU5MGXfT/quyddzOO2zxooDbf8f1wQ1JkfrAn7XH6+ozqueu/smmbPrx/64TjxChCqD9CodqV+rNK7qZlNCBlL+Gfd+ox3VPffDKfXjz0O5M6guJpG7h7Wv9YS0tafoSh52PB9onl1tPVLrWMQr797m4NHtgjeG7pbXOFXxrJXkndV+u+3RPHHHrV/8k5UfnNH82RWeLNvGVfZon9WEwKyhWLtf6jI7UECg9ej60hw1qff2hZyVHUliCS7C8leiYIDoltki/6xNzSN95r0IiBPdQy2hprDS+mWEpwsZbgYq0jt6bEc1FinYWCS6JO8vihuawt+w6OkzLPNRR+sk1DSLm1Ps/Uns/zLFAslrV45YYPNHb4fqmFWUZHDzjpDJVvfCtzByNG5Hf8Aor61CRQOmbN2vfmhqSFSg/ecNwTb0XxYPjeLft9XPFEWPK4mr1ZzUE4Ct9a6sXjre+nwT+XXuahpljrusS7jUzlMqtoeQM0s9agZDGVJ5ffX62qw8YqeBKFuU9KOT2hljft5H+9W795jfrPvk6xXbtbNon36qmt37xGTZOz/gObse9C2/rSejV+ZHj24xTxLEaYSXmPDOT51pmfHMd879W3NWR07n9g0tvQ1uPkcvPNt6t8Q+abcfPQAxU75ZRE3Wxv+OlluaaRZCvLZ3+5ytL2ueuFV1Q+7sP5H7ud/XW4TGodldqDbff22Fm9u1IaObLdatv++1r1v/JrioVPd/funfgHvJMRxIBOlAwDycCTCE2e874lJMWbFVe8Q0EpPO2gZT5SSlBqHT1KD0oxi8nMVG7lKeGpUxRiAn4H7Lr4fKlPb/X99k0qW79BzcOHatt1s7Xr7DM75fhZlb8lDRwY3fFL0fr3pCFDCrrLbTdkvhnHe/XSthuuLfixiiIWk/r0iboV+6RdZ5+p3+5YrDmvz9MbVc0asaNMcz78ec3qhp+aBEpCMrS0F4zaCkrNnhmSsgWl+qZ6rX1vraTcAamtoBSzWEt5JEGpC9p19pnRBi9EIvkzL6kQjk7xwOoH9LVtv9Wuvs2SpHVVzap9/5fS81M164ju9alJdCHpYSapKd6Usi5ZN7ycvi59P/Fg/kq2+3AoylknFJ4kKa5gXfI0SHjqi9ofScoVlJIjSW0FpVgspr49+nawdwEUAyG864l7XI3NjWpoblBjvFH1TfVqjCceNzQ3qLG5UTc8foN2NaV+Cndn405du+Baglh319GA0lbd9HVtBpQ2wkzLKFAHw4yZqb6pXq+890rKumTdxIRZa6kbXpe+n0SxpSyHtVXHLPvpt/B2AID8xD2eEmpaluONqm+uV2NzoxqbQ8uh8ozt4qn7aFkXb13O2Gc8df/hbeqb6tX8z+Y9fm6vb3m9gD2VH4JYDskfbkfCTFO8SW9vfzuvUZu2wkxHAkqybj5BJz18ZAszueqEw0y2dbnEYjFV9Si9y00AYQ+sfkA3LbxJG7Zt0NC+QzX7uNk683BGSbqDUvzZN8ebW4JNtuDS0JRY99IHL+ntV9/OGXrSw0p66GmMN6qhqSEl9GRbl17eFC/8dxFWllWqsqxSFbGK1uWyCvUo66GKsoqW8n49+qmiLKgTq1Rleeo2WzZt0dBhQ1vKW7ZP7itWocrySl396NV6d1fmp6VH9OdTkyXjg90f6J2d76jMyvIOM83erB2NO9oMM8n9dSTMACieB1Y/oK899rWW0xRvbntTX3vsa5IU+Rvyvqa9kfm2RuyT2+Ua+d/etF1bdm/JekYg/dh5Lcv1l7V/0Xef+K52Nyc+Mfvmtjd19V+v1msfvKapB01NCT2FGK3Jd5tm78CIzvP5VUsGklwBJhl2+vfo31ovKG/ZJvw4uRzLEppCoSdcni1sVZZVqjxWXrD3wJWLV2rs0WPbrXddzXUpv/eS1Luit+ZM51OTJaVHWQ/1quiVd/2YxdSzvGcRWwR0Xe6JUeWU/8hDb3655nqk/zff1n/y4fLkuiffeFL1zanXGd3VtEtfefQr+umSnybaljbvMf0NPVnW3nJ4DmJbdRsbGlX+XHnO7fIJGq2bZp/u0NHt2n1uneHp4h+ivrleP3j6B/rB0z/IexuTpYSNXKGjoqxCfSr6tISerAGlPBF6wuXZQk9lWaXeXPOmPjLmI+pR3nboKWTQ6SqS/2TduPBGbdy2USP6j9Cc6XM6fX6YRBADWpTiKYpCSp7uyHrKI+0//5ynMtLK2z0lEm/M3D7LaZCGpgY1/rONa37uoeQbZPK//2xvkOkhLKkx3qihfYemzj/MMs8w+aGN9PKU5fRR8JZNs2+35d0tGjBoQMZ24TfTXPMi25sL2dHt2n2eOdq4N/2Trb1vv/G2howYkrW9e9o/1zx2jXK596x72w1KyfVlVhZJ0Fm5aaXGDm1/9AfZnXn4mTr1kFM1oOcADewd3dfFEMQA7f3pqeSndNIDTraQsub9NdrwyoZ2T3m0GYiyjO5kO8URrpecn1hIyTen9Lkc6aco+lT20YDYgJTy8H/3Wzdt1dDhQ7P+159rlCC9PGUOSFCnLFbW7nOY/LPJenPbmxnlw/oO0z1n3FPwPstHvqdXupOV8ZUaO6mwfXLrM7fm/NkfP/L4gh4LyIUghi4r7nHtaNihHY07tL1he8ryzsadibLGHdrRsEN3Lr0z46PMu5p26at//arufu7urJNmw8Gpw5NXX2i/SnmsvCVUhOdppM/R6FHeQ30r+7YGnBz1cpZnm/uRftwsp1gqYhWdPq+jGGYfNztjrkiv8l6afdzsSNqDzsPPHqWAIIaS0dDc0BKWdjTsSAlK2xuDIJUlWOUKW+nBak/blJy82hJaskxyTS/PGXxiFXpzzZs6bOxh7YacfEZzsPeSI55d+bQ0suNn3zXl82XcUmIeZENzQ8StJYhhD7m7djftbglL4VGm8PKrr7+qPrv7pIapZP2GnSll+f5CmExVlVXqU9FHfSqDW0UfDe07NKWsqqIqczlYn7J9RR9NuWtKzlMU886aV9C+W/n2So09kNNOpeTMw8/kzbeb4mffOToSjjI+PNLGl2qn38fjce1q2qWYYi1XImnvFvWH7Ahi3URzvDnjdFx4ua3Td9lO5e1o3JH3nKOKNyqyhp/BfQa3LFdVVql3Re+UOun1qyqrVFVZpZ7lPQs+MZZTFAC6o44GpD0JR/LMy7PFLKYyK1Ms1nZICn9/ZT73G8o36JD9DomgJ/ccQSzNvOfn6doF1+r1La9rSN8h+sZx34jkv6WG5ob2w1DaKbvtja2jTOkjTh05TdervFfGiNLAXgN1UP+Dso8yhYJSOET1ruit11e8ronHTCxiTxUGpygAlIr2wlGyTtzj2tm4c68CUiwW69Do0Z6EI746o20EsZB5z89T7R9rtbNxpyRpw7YNeX1yzt21q2mX3m94X6++/2qbI05tBavwcmM8v4/yxyyWMWrUp7KPhvUdlvcoU/qoVCHnJm2MbSzYvoqNUxQA2tKZo0dmlhKQso0elVu5BvYaSEDaxxHEQq5dcG1LCEva1bRLX//b17XglQUp85nCE8dTTtM92/YxKssqW0NRRZV6VyaCUvI0XdZRphyn74p1mg4ACqG9b8DvSJm7a1dj6sh+e/tI+a7ZtMvAuVqvY9tSrwRGj6T8r7RSFivTh3p9KK+6KF0EsZBcF/vc2bhTy95a1jKiNKjXII3sPzJjlGnrxq065NBDUiaGh4NUn8o+qiyr7ORnBSAqexM66pvqc9ZreZxnEMkWOnIGkbRtk2Ut17XtQFksFmvZXUyJ5WxftBqzWMp9trKYxdSvR78ObZvyBa9ZQk6uL4Vl9AidiSAWMqL/CK3bsi6jfFjfYXrykifb3X7l4pUaO4ZPw6Gw0t98pbQ32xKsl01b2ya/862teqbUN8KUIJG6ot167e1vT0JHIYOImbV8kqutcNJeWXuho2VdkcoKaXVstfbvs3/B9wtEjSAWMmf6nJQ5YhKfnOtqkhNcwzeXZ34CNFu2SHtvyfVmLmV5IwrtLx6Pa3v99oz95Tpu+M08pVyZ5enHzfaffMpla8L7s8z95VOWbX+5RhBy7e/12Os6oM8BbdbLtr9sz6NQ9aIMImtiazSk75C92geAfQNBLCR5sc9S+NQk2pd3qApJTnotj5WrsqxS5bHyllv6vI50hXrT31C+QYcMPCTv/XUHZVam/j37R90MAOh0BLE0s46YpVlHzNI7O97R1vqt6lXRK+omdQvFDFXtBawoZBvxAQB0PwQxFFw4VCU/6dSVQxUAAHuKIIY27e1IlZmpX49+hCoAALIgiHUjUZz+ezn2Mp90AgAgB4LYPqq7zakCAKArIoiVAEIVAADdE0GswAhVAAAgXwSxdjTHm/MOVXGPa1fTrqyhqszKVBYrI1QBAIAWBLEcymPlcrma4k15h6oNZRt0yH6HRN10AACwjyCI5fChXh/iqvYAAKCo+HpvAACAiBDEAAAAIkIQAwAAiAhBDAAAICIEMQAAgIgQxAAAACJCEAMAAIgIQQwAACAiBDEAAICIEMQAAAAiQhADAACICEEMAAAgIgQxAACAiBDEAAAAIkIQAwAAiAhBDAAAICIEMQAAgIgQxAAAACJCEAMAAIhI0YOYmc0wsxfNbK2Zzc6yfoSZ/cPMnjOzFWb2yWK3CQAAoBQUNYiZWZmk2yWdKmmMpJlmNiat2jcl3e/uR0o6V9IdxWwTAABAqSj2iNhkSWvd/RV3b5A0X9LpaXVcUr9gub+kDUVuEwAAQEkoL/L+h0l6I/R4vaRj0upcL+mvZnalpD6STipymwAAAEqCuXvxdm72OUmnuPulweMLJE129ytDdb4StOMHZjZF0l2Sxrl7PG1ftZJqJWnw4MFHzZ8/v2jt3lPbt29XVVVV1M0oKfRJJvokE32Siv7IRJ9kok8ylWqfTJs2bam7V2dbV+wRsfWSDgo9Hq7MU4+XSJohSe7+tJn1lDRI0qZwJXefK2muJFVXV3tNTU2Rmrzn6urqVIrtihJ9kok+yUSfpKI/MtEnmeiTTPtinxR7jthiSYea2Wgzq1RiMv7DaXVelzRdkszscEk9Jb1T5HYBAABErqhBzN2bJF0h6VFJq5X4dORKM7vBzE4Lqn1V0mVmtlzSvZIu8mKeLwUAACgRxT41KXd/RNIjaWXfCi2vkjS12O0AAAAoNXyzPgAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQETyDmKWcL6ZfSt4PMLMJhevaQAAAF1bR0bE7pA0RdLM4PE2Sbe3t5GZzTCzF81srZnNzlHnbDNbZWYrzew3HWgTAADAPqu8A3WPcfdJZvacJLn7+2ZW2dYGZlamRFj7hKT1khab2cPuvipU51BJ35A0NdjnAR1+FgAAAPugjoyINQbByiXJzPaXFG9nm8mS1rr7K+7eIGm+pNPT6lwm6XZ3f1+S3H1TB9oEAACwz+pIEPuRpD9IOsDM5khaKOm77WwzTNIbocfrg7Kwj0j6iJk9aWbPmNmMDrQJAABgn2Xunn9ls49Kmi7JJC1w99Xt1P+cpFPc/dLg8QWSJrv7laE6f5LUKOlsScMl/VPSOHf/IG1ftZJqJWnw4MFHzZ8/P+92d5bt27erqqoq6maUFPokE32SiT5JRX9kok8y0SeZSrVPpk2bttTdq7Oty2uOmJnFJK1w93GS/t2BY6+XdFDo8XBJG7LUecbdGyW9amYvSjpU0uJwJXefK2muJFVXV3tNTU0HmtE56urqVIrtihJ9kok+yUSfpKI/MtEnmeiTTPtin+R1atLd45KWm9mIDu5/saRDzWx0MLH/XEkPp9V5UNI0STKzQUqcqnylg8cBAADY53TkU5NDJK00s0WSdiQL3f20XBu4e5OZXSHpUUllku5295VmdoOkJe7+cLDuZDNbJalZ0jXuvnkPngsAAMA+pSNB7Nt7cgB3f0TSI2ll3wotu6SvBDcAAIBuI+8g5u6Pm9lgSUcHRYv4qgkAAIA915FLHJ0taZGkzynxCcdnzeyzxWoYAABAV9eRU5PXSjo6OQoWfKHr3yT9rhgNAwAA6Oo68oWusbRTkZs7uD0AAABCOjIi9hcze1TSvcHjcyT9ufBNAgAA6B46Mln/GjM7U9JxSnyz/lx3/0PRWgYAANDF5R3EzGy0pEfc/YHgcS8zG+XurxWrcQAAAF1ZR+Z4/VZSPPS4OSgDAADAHuhIECt394bkg2C5svBNAgAA6B46EsTeMbOWyxmZ2emS3i18kwAAALqHjnxq8nJJ88zsx0pM1n9D0oVFaRUAAEA30JFPTb4s6Vgzq5Jk7r6teM0CAADo+to9NWlmnzazkaGir0haaGYPB5+kBAAAwB7IZ47YHEnvSJKZfUrS+ZL+H0kPS/pp8ZoGAADQteUTxNzddwbLZ0q6y92XuvvPJe1fvKYBAAB0bfkEMTOzKjOLSZouaUFoXc/iNAsAAKDry2ey/q2SlknaKmm1uy+RJDM7UtLGIrYNAACgS2s3iLn73cHFvg+QtDy06i1JFycfmNlYd19Z+CYCAAB0TXl9fYW7vynpzbSy9NGwX0uaVKB2AQAAdHkd+Wb99lgB9wUAANDlFTKIeQH3BQAA0OUVMogBAACgAwoZxBoKuC8AAIAub6+CmJl9NLns7sfufXMAAAC6j70dEftrQVoBAADQDbX79RVm9qNcqyQNKGxzAAAAuo98vkfsYklflaPnc7gAABtlSURBVFSfZd3MwjYHAACg+8gniC2W9IK7P5W+wsyuL3iLAAAAuol8gthnJe3OtsLdRxe2OQAAAN1HPpP1q9x9Z9FbAgAA0M3kE8QeTC6Y2e+L2BYAAIBuJZ8gFr6G5IeL1RAAAIDuJp8g5jmWAQAAsBfymaw/wcy2KjEy1itYVvDY3b1f0VoHAADQhbUbxNy9rDMaAgAA0N0U8qLfAAAA6ACCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESk6EHMzGaY2YtmttbMZrdR77Nm5mZWXew2AQAAlIKiBjEzK5N0u6RTJY2RNNPMxmSp11fSlyU9W8z2AAAAlJJij4hNlrTW3V9x9wZJ8yWdnqXef0u6WdLuIrcHAACgZJi7F2/nZp+VNMPdLw0eXyDpGHe/IlTnSEnfdPezzKxO0tXuviTLvmol1UrS4MGDj5o/f37R2r2ntm/frqqqqqibUVLok0z0SSb6JBX9kYk+yUSfZCrVPpk2bdpSd8869aq8yMe2LGUtyc/MYpJukXRRezty97mS5kpSdXW119TUFKaFBVRXV6dSbFeU6JNM9Ekm+iQV/ZGJPslEn2TaF/uk2Kcm10s6KPR4uKQNocd9JY2TVGdmr0k6VtLDTNgHAADdQbGD2GJJh5rZaDOrlHSupIeTK919i7sPcvdR7j5K0jOSTst2ahIAAKCrKWoQc/cmSVdIelTSakn3u/tKM7vBzE4r5rEBAABKXbHniMndH5H0SFrZt3LUrSl2ewAAAEoF36wPAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARAhiAAAAESGIAQAARIQgBgAAEBGCGAAAQEQIYgAAABEhiAEAAESEIAYAABARghgAAEBECGIAAAARIYgBAABEhCAGAAAQEYIYAABARIoexMxshpm9aGZrzWx2lvVfMbNVZrbCzBaY2chitwkAAKAUFDWImVmZpNslnSppjKSZZjYmrdpzkqrdfbyk30m6uZhtAgAAKBXFHhGbLGmtu7/i7g2S5ks6PVzB3f/h7juDh89IGl7kNgEAAJQEc/fi7dzss5JmuPulweMLJB3j7lfkqP9jSW+5+3eyrKuVVCtJgwcPPmr+/PlFa/ee2r59u6qqqqJuRkmhTzLRJ5nok1T0Ryb6JBN9kqlU+2TatGlL3b0627ryIh/bspRlTX5mdr6kakknZFvv7nMlzZWk6upqr6mpKVATC6eurk6l2K4o0SeZ6JNM9Ekq+iMTfZKJPsm0L/ZJsYPYekkHhR4Pl7QhvZKZnSTpWkknuHt9kdsEAABQEoo9R2yxpEPNbLSZVUo6V9LD4QpmdqSkOyWd5u6bitweAACAklHUIObuTZKukPSopNWS7nf3lWZ2g5mdFlT7nqQqSb81s2Vm9nCO3QEAAHQpxT41KXd/RNIjaWXfCi2fVOw2AAAAlCK+WR8AACAiBDEAAICIEMQAAAAiQhADAACICEEMAAAgIgQxAACAiBDEAAAAIkIQAwAAiAhBDAAAICIEMQAAgIgQxAAAACJCEAMAAIgIQQwAACAiBDEAAICIEMQAAAAiQhADAACISHnUDSiUxsZGrV+/Xrt3746sDf3799fq1asjO34pytYnPXv21PDhw1VRURFRqwAAKA1dJoitX79effv21ahRo2RmkbRh27Zt6tu3byTHLlXpfeLu2rx5s9avX6/Ro0dH2DIAAKLXZU5N7t69WwMHDowshCE/ZqaBAwdGOnIJAECp6DJBTBIhbB/BzwkAgIQuFcSitHnzZk2dOlUTJ07UgQceqGHDhmnixImaOHGiGhoa8trHxRdfrBdffLHNOrfffrvmzZtXiCbroYce0sSJEzVhwgSNGTNGP//5zwuyXwAAkJ8uM0esw+bNk669Vnr9dWnECGnOHGnWrD3e3cCBA/Xkk0+qb9++uv7661VVVaWrr746pY67y90Vi2XPv7/4xS/aPc6XvvSlPW5jWH19vb74xS9qyZIlGjp0qOrr67Vu3bq92md7zw8AAKTqnu+Y8+ZJtbXSunWSe+K+tjZRXmBr167VuHHjdPnll2vSpEnauHGjamtrVV1drbFjx+qGG25oqXvcccdp2bJlampq0oABAzR79mxNmDBBU6ZM0aZNmyRJ3/zmN3Xrrbe21J89e7YmT56sww47TE899ZQkaceOHTrrrLM0YcIEzZw5U9XV1Vq2bFlKu7Zs2SJ313777SdJ6tGjhz7ykY9Ikt566y2dfvrpGj9+vCZMmKBnn31WknTzzTdr3LhxGjdunG677bacz+/Pf/6zpkyZokmTJumiiy7Sjh07Ct6vAAB0BV0ziF11lVRTk/t2ySXSzp2p2+zcmSjPtc1VV+1xc1atWqVLLrlEzz33nIYNG6abbrpJS5Ys0fLly/XYY49p1apVGdts2bJFJ5xwgpYvX64pU6bo7rvvzrpvd9eiRYv0ve99ryXU3XbbbTrwwAO1fPlyzZ49W88991zGdgcccIBOOeUUjRw5Uuedd57uvfdexeNxSYlRt0984hNasWKFli5dqsMPP1yLFi3SvHnztGjRIj399NO64447tGLFioznV1FRoZtuukkLFizQv/71L40dO1Y//OEP97jvAADoyrpmEGtPfX3HyvfSwQcfrKOPPrrl8b333qtJkyZp0qRJWr16ddYg1qtXL5166qmSpKOOOkqvvfZa1n2feeaZGXUWLlyoc889V5I0YcIEjR07Nuu299xzjx577DFVV1frpptuUm1trSSprq5OX/jCFyRJ5eXl6tevn/75z3/qrLPOUu/evdW3b1+dccYZWrhwYcbze+qpp7Rq1Sp97GMf08SJE3X//ffnbDsAAN1d15wjFpy6y2nUqMTpyHQjR0p1dQVvTp8+fVqW16xZox/+8IdatGiRBgwYoPPPPz/rVzlUVla2LJeVlampqSnrvnv06JFRx93zbtv48eM1fvx4nXfeeTr88MNbJuynf7KxrX2Gn5+7a8aMGfr1r38tie9WAwCgLd1zRGzOHKl379Sy3r0T5UW2detW9e3bV/369dPGjRv16KOPFvwYxx13nO6//35J0vPPP591xG3r1q164oknWh4vW7ZMI0eOlCRNmzZNP/3pTyVJzc3N2rp1q44//nj94Q9/0K5du7R9+3Y99NBD+vjHP56x34997GN6/PHH9corr0hKzFdbs2ZNwZ8jAABdQdccEWtP8tORBfzUZL4mTZqkMWPGaNy4cfrwhz+sqVOnFvwYV155pS688EKNHz9ekyZN0rhx49S/f/+UOu6uG2+8UZdddpl69eqlqqqqlnloP/7xj3XZZZfpzjvvVHl5ue68805NnjxZM2fObDkF+cUvflFHHHGE1q5dm7LfwYMH66677tI555yjhoYGxeNx3XTTTTr00EML/jwBANjXWUdOY5WK6upqX7JkSUrZ6tWrdfjhh0fUooRSOQ3X1NSkpqYm9ezZU2vWrNHJJ5+sNWvWqLy883N3rj4phZ9XVOrq6lRTUxN1M0oKfZKK/shEn2SiTzKVap+Y2VJ3r862rnuOiHVx27dv1/Tp09XU1CR3bxnZAgAApYV35y5owIABWrp0adTNAAAA7eiek/UBAABKAEEMAAAgIgQxAACAiBDEAAAAIkIQK6C3335b5557rg4++GCNGTNGn/zkJ/XSSy9p9OjRevHFF1PqXnXVVbr55ptTyuLxuL785S9r3LhxOuKII3T00Ufr1Vdf7cynAAAAOlG3DWLznp+nUbeOUuzbMY26dZTmPT9vr/bn7jrvvPNUU1Ojl19+WatWrdJ3v/vdlnA2f/78lrrxeFy/+93vdM4556Ts47777tOGDRu0YsUKPf/88/rDH/6gAQMG7FW7cl0aCQAARK9bBrF5z89T7R9rtW7LOrlc67asU+0fa/cqjP3jH/9QRUWFLr/88payiRMn6uMf/7hmzpyZEsSeeOIJjRo1quWSQkkbN27UkCFDFIslfizDhw/Xhz70IUnSX/7yF02aNEkTJkzQ9OnTJUnvvfeezjjjDI0fP17HHnusVqxYIUm6/vrrVVtbq5NPPlkXXnihmpubdc011+joo4/W+PHjdeedd+7x8wQAAIXTJb9H7Kq/XKVlby3Luf6Z9c+ovrk+pWxn405d8tAl+tnSn2XdZuKBE3XrjNwXE3/hhRc0ceLErOvGjx+vWCym5cuXa8KECZo/f75mzpyZUe/ss8/Wcccdp3/+85+aPn26zj//fB155JF65513dNlll+mJJ57Q6NGj9d5770mSrrvuOh155JF68MEH9fe//10XXnihli1LPO+lS5dq4cKF6tWrl+bOnav+/ftr8eLFqq+v19SpU3XyySdr9OjROZ8PAAAovm45IpYewtorL4TkqFhTU5Meeughfe5zn8uoM3z4cL344ou68cYbFYvFNH36dC1YsEDPPPOMjj/++JbgtN9++0mSFi5cqAsuuECSdOKJJ2rz5s3asmWLJOm0005Tr169JEl//etf9atf/UoTJ07UMccco82bN3MhbgAASkCXHBFra+RKkkbdOkrrtqzLKB/Zf6TqLqrbo2OOHTtW9913X871M2fO1Mknn6wTTjhB48eP1wEHHJC1Xo8ePXTqqafq1FNP1eDBg/Xggw/qE5/4hMwso26264Qm6/Xp0yel3m233aZTTjmlo08LAAAUUbccEZszfY56V/ROKetd0Vtzps/Z432eeOKJqq+v189+1npqc/HixXr88cclSQcffLAGDhyo2bNnZz0tKUn/+te/tGHDBkmJCf0rVqzQyJEjNWXKFD3++OMtn6BMnpo8/vjjNW9eYl5bXV2dBg0apH79+mXs95RTTtFPfvITNTY2SpJeeukl7dixY4+fKwAAKIxuGcRmHTFLcz89VyP7j5TJNLL/SM399FzNOmLWHu/TzPSb3/xGjz32mA4++GCNHTtW119/vYYOHdpSZ+bMmfr3v/+tz3zmM1n3sWnTJn3605/WuHHjNH78eJWXl+uKK67Q/vvvr7lz5+rMM8/UhAkTWj5tef3112vJkiUaP368Zs+erV/+8pdZ93vppZdqzJgxmjRpksaNG6cvfOELfJoSAIASYNlOb5W66upqX7JkSUrZ6tWrdfjhh0fUooRt27apb9++kbah1OTqk1L4eUWlrq5ONTU1UTejpNAnqeiPTPRJJvokU6n2iZktdffqbOu65YgYAABAKSCIAQAARIQgBgAAEJEuFcT2xflu3RE/JwAAErpMEOvZs6c2b97Mm3yJc3dt3rxZPXv2jLopAABErst8oevw4cO1fv16vfPOO5G1Yffu3QSMNNn6pGfPnho+fHhELQIAoHQUPYiZ2QxJP5RUJunn7n5T2voekn4l6ShJmyWd4+6vdfQ4FRUVkV87sa6uTkceeWSkbSg19AkAALkV9dSkmZVJul3SqZLGSJppZmPSql0i6X13P0TSLZL+p5htAgAAKBXFniM2WdJad3/F3RskzZd0elqd0yUlvxL+d5KmW7YLKwIAAHQxxQ5iwyS9EXq8PijLWsfdmyRtkTSwyO0CAACIXLHniGUb2Ur/WGM+dWRmtZJqg4fbzezFvWxbMQyS9G7UjSgx9Ekm+iQTfZKK/shEn2SiTzKVap+MzLWi2EFsvaSDQo+HS9qQo856MyuX1F/Se+k7cve5kuYWqZ0FYWZLcl1LqruiTzLRJ5nok1T0Ryb6JBN9kmlf7JNin5pcLOlQMxttZpWSzpX0cFqdhyV9Plj+rKS/O18GBgAAuoGijoi5e5OZXSHpUSW+vuJud19pZjdIWuLuD0u6S9KvzWytEiNh5xazTQAAAKWi6N8j5u6PSHokrexboeXdkj5X7HZ0kpI+dRoR+iQTfZKJPklFf2SiTzLRJ5n2uT4xzgICAABEo8tcaxIAAGBfQxDLk5ndbWabzOyFUNl+ZvaYma0J7j8UlJuZ/cjM1prZCjObFF3LiydHn1xvZm+a2bLg9snQum8EffKimZ0STauLy8wOMrN/mNlqM1tpZv8ZlHfb10obfdJtXytm1tPMFpnZ8qBPvh2UjzazZ4PXyX3Bh5xkZj2Cx2uD9aOibH8xtNEn95jZq6HXycSgvMv/7kiJK9SY2XNm9qfgcbd9jSRl6ZN9+jVCEMvfPZJmpJXNlrTA3Q+VtCB4LCUu6XRocKuV9JNOamNnu0eZfSJJt7j7xOD2iCRZ4tJW50oaG2xzhyUugdXVNEn6qrsfLulYSV8Knnt3fq3k6hOp+75W6iWd6O4TJE2UNMPMjlXiEm+3BK+T95W4BJzUPS4Fl6tPJOma0OtkWVDWHX53JOk/Ja0OPe7Or5Gk9D6R9uHXCEEsT+7+hDK/3yx8eaZfSjojVP4rT3hG0gAzG9I5Le08Ofokl9MlzXf3end/VdJaJS6B1aW4+0Z3/1ewvE2JPxbD1I1fK230SS5d/rUS/Ly3Bw8rgptLOlGJS71Jma+TLn0puDb6JJcu/7tjZsMl/YeknwePTd34NSJl9kk79onXCEFs7wx2941S4s1G0gFBeT6XdurKrgiGge9OnoJTN+yT4NTAkZKeFa8VSRl9InXj10pwemWZpE2SHpP0sqQPgku9SanPu1tcCi69T9w9+TqZE7xObjGzHkFZd3id3Crpa5LiweOB6uavEWX2SdI++xohiBVHXpdt6qJ+IulgJU4tbJT0g6C8W/WJmVVJ+r2kq9x9a1tVs5R1yX7J0ifd+rXi7s3uPlGJK45MlnR4tmrBfbfsEzMbJ+kbkj4q6WhJ+0n6elC9S/eJmX1K0iZ3XxouzlK127xGcvSJtI+/Rghie+ft5DBncL8pKM/n0k5dkru/HfwxjUv6mVpPKXWbPjGzCiUCxzx3fyAo7tavlWx9wmslwd0/kFSnxPy5AZa41JuU+rxb+sTauBRcVxHqkxnBqW1393pJv1D3eZ1MlXSamb0mab4SpyRvVfd+jWT0iZn9777+GiGI7Z3w5Zk+L+mhUPmFwSc2jpW0JXlaqqtLO//+GUnJT1Q+LOnc4JM9o5WYPLmos9tXbMGcjLskrXb3/y+0qtu+VnL1SXd+rZjZ/mY2IFjuJekkJebO/UOJS71Jma+TLn0puBx98u/QPzCmxHyo8Ouky/7uuPs33H24u49S4sMrf3f3WerGr5EcfXL+vv4aKfo363cVZnavpBpJg8xsvaTrJN0k6X4zu0TS62q9QsAjkj6pxCTjnZIu7vQGd4IcfVITfHTYJb0m6QuSFFza6n5Jq5T4FN2X3L05inYX2VRJF0h6PpjrIkn/pe79WsnVJzO78WtliKRfBp8GjUm6393/ZGarJM03s+9Iek6JACt1j0vB5eqTv5vZ/kqcZlom6fKgfnf43cnm6+q+r5Fc5u3LrxG+WR8AACAinJoEAACICEEMAAAgIgQxAACAiBDEAAAAIkIQAwAAiAhBDECHmNmNZlZjZmeY2ez2t0jZdn8ze9bMnjOzj4fK/2Bmy8xsrZltCZaXmdnHOrDvL5nZrHbqHGNmt3SkzW3s6ztm9maorcvMrG8h9t3BdlxqZrd29nEBFAbfIwago46RdIOk76r14sP5mi7p3+7++XChu39GksysRtLV7v6pbBubWXnoOnsp3P329g4eXLvw2fbqdcD33J0QBGCPMSIGIC9m9j0zW6HE9dyelnSppJ+Y2bey1B1pZguCi/AuMLMRwZe33izpk8HoUa88j7vezP6PmT0p6TNmdrmZLTaz5Wb22+R+ghGqq4LlhWZ2k5ktMrMXkyNrZnaSmT0Yqn+XmT1uZq+Y2ZdCx/y2mf3bzB4zs/uS+82zvV8zs7nB8kQze97MepnZsWb2dDAa+KSZHRrUudTMHjCzP5nZq2b2RTO7Jqj3lLV+2/xCM7s12MfzZlad5diDg30tCZ77sUH5iUF/LTOzf5lZn3yfD4DiIogByIu7X6NE+LpHiTC2wt3Hu/sNWar/WNKv3H28pHmSfuTuyyR9S9J97j7R3Xd14PA73H2qu/9W0m/d/Wh3nyDpZUkX5djG3H2ypGuC42bzEUmfUOI6jzeYWVkQXj4laYKks4Lnmss1odOSfwvKvi9prJmdrsR17y4LnutqSce5+5GS/lvSd0L7GSvpnKAd/yPp/aDeUknnh+r1cPcpkv5T0s+ztOdHkm5292pJZ4fqXCOpNrig9vGSdrfxnAB0Ik5NAuiII5W4hMhHlbgEUS5TJJ0ZLP9aiZGwvXFfaHm8md0gaYCkvpL+lGOb5AXXl0oalaPOn9y9QdImM3tP0v6SjpP0YHAB4Xozy7V/KcupSXePm9lFSvTTj939mWDVAEm/MrODs+zn7+6+Q9IOM9su6Y9B+fNKhMWke4Nj/N3MDjCzqrT9nCTpMDNLPv5QMGL4pKRbzew3kn7v7tvbeE4AOhFBDEC7gtOK90gaLuldSb0TxbZM0pQ8Rrf29lpqO0LLv5J0qru/YGaXKjGKlE19cN+s3H/r6kPLyXqWo25HHCppu6ShobI5kh519zvM7BBJf8nRjnjocVypbU/vx/THJmlyEC7DvmNmD0v6D0mLzazG3dfk/WwAFA2nJgG0y92XBae1XpI0RtLfJZ3SxinGp9R60eFZkhYWsDl9JL1lZhWSzivgfpMWSjrNzHoEn4L8ZEc2DuZ03aLExc6HmdkZwar+kt4Mli/aw7adExyjRtLbwSha2N8khee6TQzuD3b3Fe5+oxIXij5sD48PoMAIYgDyYmb7KzF3KS7po+7e1qnJL0u6OJjcf4ESc5oK5VuSFkl6TG2fHt0j7v60EqNVK5T4VOhiSVtyVA/PEVtmZgcpMU/rh+6+VtLFkr5nZoOUmPv1veBDB3tqq5k9Jek2SZdlWf8lSVODD0msCtW52sxeCH4eH0j66160AUABmfvenjEAgK7FzKrcfXvw6cKFkj7v7isibtNCSVcEH3oA0EUwRwwAMt1lZodJ6inp7qhDGICuixExAACAiDBHDAAAICIEMQAAgIgQxAAAACJCEAMAAIgIQQwAACAiBDEAAICI/F90k935lu2jqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(figsize = (10, 6))\n",
    "axes.fill_between(train_sizes, train_scores_mean + train_scores_std, train_scores_mean - train_scores_std, alpha = 0.1, color = 'r')\n",
    "axes.fill_between(train_sizes, cv_scores_mean + cv_scores_std, cv_scores_mean - cv_scores_std, alpha = 0.1, color = 'g')\n",
    "axes.plot(train_sizes, train_scores_mean, c = 'r', ls = '-', marker = 'o', label = 'Training Score')\n",
    "axes.plot(train_sizes, cv_scores_mean, c = 'g', ls = '-', marker = 'o', label = 'CV Score')\n",
    "axes.grid()\n",
    "axes.set_title('Learning Curve')\n",
    "axes.set_xlabel('# of Training Examples')\n",
    "axes.set_ylabel('F1_Score')\n",
    "axes.set_ylim(0, 1.1)\n",
    "axes.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So it does not seem like our model is subject to high bias or high variance issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for high bias, we usually have several solutions:\n",
    "1. Use a more complex model\n",
    "2. Create new features using feature engineering\n",
    "\n",
    "For high variance, solutions could be:\n",
    "1. Get more data\n",
    "2. Use a less complex model\n",
    "3. Using regularizations (Especially L1 Reg results in sparse weights)\n",
    "4. Dimensionality Reduction (Feature Selection or Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speaking of dimensionality reduction, here are several example types:\n",
    "1. PCA: dimensionality reduction based on principal components\n",
    "2. Linear Discriminant Analysis: Supervised dimensionality reduction method based on response classes\n",
    "3. Kernel PCA: PCA on kernels which could be non-linear transformations on existing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's say if we would like to try PCA for exploring, we can add PCA to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pipe_svm = make_pipeline(StandardScaler(), PCA(n_components = 2, random_state = 1), SVC(kernel = 'linear', probability = True, random_state = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_pred     0   1\n",
       "y_actual        \n",
       "0         35   3\n",
       "1          7  58"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svm.fit(X_train_sub, y_train_sub)\n",
    "pred_cv = pipe_svm.predict(X_cv)\n",
    "y_actual = pd.Series(y_cv, name = 'y_actual').reset_index(drop = True)\n",
    "y_pred = pd.Series(pred_cv, name = 'y_pred').reset_index(drop = True)\n",
    "pd.crosstab(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we look at the f1 score and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score is: 0.875\n",
      "The recall score is: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(f'The f1 score is: {f1_score(y_actual, y_pred, pos_label = 0)}')\n",
    "print(f'The recall score is: {recall_score(y_actual, y_pred, pos_label = 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The metrics are worse than the ones generated if we use all features to train the model, and this is what we expected. However, the metrics are not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One thing about unbalanced classes is that if we have too few instances of one class, the classifier might have limited predictability on that class because the trainings largely take place for the majority class. For example, if we have binary class (0, 1) and their class instances are (1, 99) for training, then the model would have hard time predicting for class 0 in the test set because it does not have enough examples to train on. In general, to alleviate this issue, we have two ways:\n",
    "1. In the cost function, we penalize incorrect classification of the minority class more\n",
    "2. Use up/down-sampling to adjust class distribution to balance the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actually, #1 above was already used in our model by setting class_weight = 'balanced' (default). But let's explore #2 and see how it can work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of instances in class 0 is 191; the # of instances in class 1 is 321\n"
     ]
    }
   ],
   "source": [
    "cl, cl_cnt = np.unique(y_train, return_counts = True)\n",
    "print(f'The # of instances in class {cl[0]} is {cl_cnt[0]}; the # of instances in class {cl[1]} is {cl_cnt[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we would like to up-sample class 0 to have the same # of instances as class 1, then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "cnt_diff = cl_cnt[1] - cl_cnt[0]\n",
    "X_train_add, y_train_add = resample(X_train[y_train == 0], y_train[y_train == 0], replace = True, n_samples = cnt_diff, random_state = 1)\n",
    "X_train_bal = np.vstack((X_train, X_train_add))\n",
    "y_train_bal = np.hstack((y_train, y_train_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of instances in class 0 is 321; the # of instances in class 1 is 321\n"
     ]
    }
   ],
   "source": [
    "cl, cl_cnt = np.unique(y_train_bal, return_counts = True)\n",
    "print(f'The # of instances in class {cl[0]} is {cl_cnt[0]}; the # of instances in class {cl[1]} is {cl_cnt[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use K-fold cross-validaton this time for performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = make_pipeline(StandardScaler(), SVC(kernel = 'linear', random_state = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 1)\n",
    "scores = []\n",
    "for train_idx, cv_idx in skf.split(X_train_bal, y_train_bal):\n",
    "    X_train_ = X_train_bal[train_idx]\n",
    "    y_train_ = y_train_bal[train_idx]\n",
    "    X_cv_ = X_train_bal[cv_idx]\n",
    "    y_cv_ = y_train_bal[cv_idx]\n",
    "    \n",
    "    pipe_svm.fit(X_train_, y_train_)\n",
    "    pred_ = pipe_svm.predict(X_cv_)\n",
    "    score = f1_score(y_cv_, pred_, pos_label = 0)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f1_score for the balanced classes is: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(f'The average f1_score for the balanced classes is: {round(np.mean(scores), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we would like to explore the use of GridSearchCV to find the best hyper-parameters and nesting it with cross_val_score to compare model performances. We would compare the performances between the svm and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_range = [0.0001, 0.001, 0.1, 1, 10, 100, 1000]\n",
    "param_grid_svm = [{'svc__C': numeric_range, 'svc__kernel': ['linear']}, \n",
    "                  {'svc__C': numeric_range, 'svc__kernel': ['rbf'], 'svc__gamma': numeric_range}]\n",
    "gs_svm = GridSearchCV(estimator = pipe_svm, param_grid = param_grid_svm, scoring = f1_scorer, n_jobs = -1, cv = 10)\n",
    "scores_svm = cross_val_score(estimator = gs_svm, X = X_train, y = y_train, scoring = f1_scorer, cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f1_score from the svm model is 0.9681036704720916 with standard deviation of 0.02622073371797614.\n"
     ]
    }
   ],
   "source": [
    "print(f'The average f1_score from the svm model is {np.mean(scores_svm)} \\\n",
    "with standard deviation of {np.std(scores_svm)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression(random_state = 1, class_weight = 'balanced', n_jobs = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = [{'logisticregression__penalty': ['l1', 'l2'], 'logisticregression__C': numeric_range, 'logisticregression__solver': ['liblinear']},\n",
    "                {'logisticregression__penalty': ['l2'], 'logisticregression__C': numeric_range, 'logisticregression__solver': ['lbfgs']}]\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr, param_grid = param_grid_lr, scoring = f1_scorer, n_jobs = -1, cv = 10)\n",
    "scores_lr = cross_val_score(estimator = gs_lr, X = X_train, y = y_train, scoring = f1_scorer, cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f1_score from the LogisticRegression model is 0.9711055184739396 with standard deviation of 0.029929681806280767.\n"
     ]
    }
   ],
   "source": [
    "print(f'The average f1_score from the LogisticRegression model is {np.mean(scores_lr)} \\\n",
    "with standard deviation of {np.std(scores_lr)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results are pretty close, let's say the Logistic Regression Model is the better one and we would like to use it on the test set for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr.fit(X_train, y_train)\n",
    "pred = gs_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for the test set using Logistic Regression Model is 0.952\n"
     ]
    }
   ],
   "source": [
    "print(f'The f1 score for the test set using Logistic Regression Model is {round(f1_score(y_test, pred, pos_label = 0), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems the Logistic Regression Model is also doing well for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
